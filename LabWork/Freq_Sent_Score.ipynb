{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Freq_Sent_Score.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitaliKambli/J025_NLP/blob/master/LabWork/Freq_Sent_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYENeYFvZ1wr",
        "colab_type": "code",
        "outputId": "85819482-982c-4ed6-b0e2-7d8408962ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import urllib, json\n",
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)\n",
        "df=df.head(3)\n",
        "print(df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
            "0  A32T2H8150OJLU  B00000JBLH  ...     1094169600   09 3, 2004\n",
            "1  A3MAFS04ZABRGO  B00000JBLH  ...     1197676800  12 15, 2007\n",
            "2  A1F1A0QQP2XVH5  B00000JBLH  ...     1293840000   01 1, 2011\n",
            "\n",
            "[3 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GPclPpxmYVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "391e6b31-62d7-406a-c2c8-edcf333052fc"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHbwLMwbm-Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls drive/\"My Drive\"\n",
        "f = open(\"drive/My Drive/negwords.txt\")\n",
        "\n",
        "lineList = list()\n",
        "ngtv_words= [line.rstrip('\\n') for line in open(\"drive/My Drive/negwords.txt\",encoding=\"ISO-8859-1\")]\n",
        "#print(neg_words)\n",
        "\n",
        "lineList = list()\n",
        "pstv_words= [line.rstrip('\\n') for line in open(\"drive/My Drive/poswords.txt\",encoding=\"ISO-8859-1\")]\n",
        "#print(pos_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF28-glNaHE1",
        "colab_type": "code",
        "outputId": "4f9313b2-f1b5-4cfc-b949-f003a2a753e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "def pos_adj(sentence):\n",
        "  adjectives=dict()\n",
        "  freq_pos=0\n",
        "  pos_adj=[]\n",
        "  d=dict()\n",
        "  adjectives = [token for token, pos in nltk.pos_tag(word_tokenize(sentence)) if pos.startswith('J')]\n",
        "  for i in range(len(adjectives)):\n",
        "    if adjectives[i] in pstv_words:\n",
        "      pos_adj.append(adjectives[i])\n",
        "      freq_pos+=1\n",
        "  d[\"pos_adj\"]=pos_adj\n",
        "  d[\"freq_pos\"]=freq_pos\n",
        "  return d\n",
        "\n",
        "def neg_adj(sentence):\n",
        "  adjectives=dict()\n",
        "  neg_adj=[]\n",
        "  freq_neg=0\n",
        "  d=dict()\n",
        "  adjectives = [token for token, pos in nltk.pos_tag(word_tokenize(sentence)) if pos.startswith('J')]\n",
        "  for i in range(len(adjectives)):\n",
        "    if adjectives[i] in ngtv_words:\n",
        "      neg_adj.append(adjectives[i])\n",
        "      freq_neg+=1\n",
        "  d[\"neg_adj\"]=neg_adj\n",
        "  d[\"freq_neg\"]=freq_neg\n",
        "  return d\n",
        "\n",
        "df['reviewText_pos_adj']= df['reviewText'].apply(pos_adj)\n",
        "df['reviewText_neg_adj']= df['reviewText'].apply(neg_adj)\n",
        "print(df['reviewText_pos_adj'])\n",
        "print(df['reviewText_neg_adj'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'pos_adj': ['powerful', 'best', 'good', 'soli...\n",
            "1    {'pos_adj': ['satisfied', 'best', 'golden', 'b...\n",
            "2    {'pos_adj': ['flawless', 'cheaper', 'available...\n",
            "Name: reviewText_pos_adj, dtype: object\n",
            "0            {'neg_adj': ['difficult'], 'freq_neg': 1}\n",
            "1    {'neg_adj': ['disappointing', 'futile'], 'freq...\n",
            "2               {'neg_adj': ['hollow'], 'freq_neg': 1}\n",
            "Name: reviewText_neg_adj, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrtQLJENaszp",
        "colab_type": "code",
        "outputId": "b8649367-1f23-4384-e433-1c019b822b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GMooZUUljVf",
        "colab_type": "code",
        "outputId": "ee0fd2b0-571b-43df-d834-baf37ff9cffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import re\n",
        "import string\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "def sentiment_analyzer_scores(text):\n",
        "    score = analyzer.polarity_scores(text)\n",
        "    #print(text)\n",
        "    print(score)\n",
        "\n",
        "df['reviewText_score']= df['reviewText'].apply(sentiment_analyzer_scores)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.039, 'neu': 0.781, 'pos': 0.18, 'compound': 0.9831}\n",
            "{'neg': 0.029, 'neu': 0.871, 'pos': 0.099, 'compound': 0.9963}\n",
            "{'neg': 0.137, 'neu': 0.756, 'pos': 0.108, 'compound': -0.2617}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}