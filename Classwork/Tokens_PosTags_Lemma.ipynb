{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokens_PosTags_Lemma.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitaliKambli/J025_NLP/blob/master/Classwork/Tokens_PosTags_Lemma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPMM_fYd45Yk",
        "colab_type": "code",
        "outputId": "8b949563-2557-4823-b15b-88252207999c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import urllib, json\n",
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)\n",
        "df=df.head(10)\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
            "0  A32T2H8150OJLU  B00000JBLH  ...     1094169600   09 3, 2004\n",
            "1  A3MAFS04ZABRGO  B00000JBLH  ...     1197676800  12 15, 2007\n",
            "2  A1F1A0QQP2XVH5  B00000JBLH  ...     1293840000   01 1, 2011\n",
            "3   A49R5DBXXQDE5  B00000JBLH  ...     1145404800  04 19, 2006\n",
            "4  A2XRMQA6PJ5ZJ8  B00000JBLH  ...     1375574400   08 4, 2013\n",
            "5  A2JFOHC9W629IE  B00000JBLH  ...     1011744000  01 23, 2002\n",
            "6  A38NELQT98S4H8  B00000JBLH  ...     1168992000  01 17, 2007\n",
            "7   AA8M6331NI1EN  B00000JBLH  ...     1384387200  11 14, 2013\n",
            "8  A25C2M3QF9G7OQ  B00000JBLU  ...     1291680000   12 7, 2010\n",
            "9  A1RTVWTWZSIC94  B00000JBLU  ...     1385942400   12 2, 2013\n",
            "\n",
            "[10 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1bIDv5vEow_",
        "colab_type": "code",
        "outputId": "d83ac51f-7240-4188-b9c8-4068acf56157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def nltk_token(sentence):\n",
        "  tokens=dict()\n",
        "  tokens[\"Tokens\"] = word_tokenize(sentence)\n",
        "  return tokens\n",
        "\n",
        "df['reviewText_tokens']= df['reviewText'].apply(nltk_token)\n",
        "print(df[\"reviewText_tokens\"])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Tokens': ['I', 'bought', 'my', 'first', 'HP1...\n",
            "1    {'Tokens': ['WHY', 'THIS', 'BELATED', 'REVIEW'...\n",
            "2    {'Tokens': ['I', 'have', 'an', 'HP', '48GX', '...\n",
            "3    {'Tokens': ['I', ''ve', 'started', 'doing', 'm...\n",
            "4    {'Tokens': ['For', 'simple', 'calculations', '...\n",
            "5    {'Tokens': ['While', 'I', 'do', 'n't', 'have',...\n",
            "6    {'Tokens': ['I', ''ve', 'had', 'an', 'HP', '12...\n",
            "7    {'Tokens': ['Bought', 'this', 'for', 'my', 'bo...\n",
            "8    {'Tokens': ['This', 'is', 'a', 'well-designed'...\n",
            "9    {'Tokens': ['I', 'love', 'this', 'calculator',...\n",
            "Name: reviewText_tokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Xw7x6YXYnm",
        "colab_type": "code",
        "outputId": "1b6ae3fb-03a2-40ef-db48-519911644944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "tokenizer = MWETokenizer()\n",
        "\n",
        "def mwe_token(sentence):\n",
        "  Mwe=dict()\n",
        "  Mwe[\"MWE_tokens\"]=tokenizer.tokenize(sentence)\n",
        "  return Mwe\n",
        "\n",
        "df['reviewText_mweTokens']= df['reviewText'].apply(mwe_token)\n",
        "print(df[\"reviewText_mweTokens\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'MWE_tokens': ['I', ' ', 'b', 'o', 'u', 'g', ...\n",
            "1    {'MWE_tokens': ['W', 'H', 'Y', ' ', 'T', 'H', ...\n",
            "2    {'MWE_tokens': ['I', ' ', 'h', 'a', 'v', 'e', ...\n",
            "3    {'MWE_tokens': ['I', ''', 'v', 'e', ' ', 's', ...\n",
            "4    {'MWE_tokens': ['F', 'o', 'r', ' ', 's', 'i', ...\n",
            "5    {'MWE_tokens': ['W', 'h', 'i', 'l', 'e', ' ', ...\n",
            "6    {'MWE_tokens': ['I', ''', 'v', 'e', ' ', 'h', ...\n",
            "7    {'MWE_tokens': ['B', 'o', 'u', 'g', 'h', 't', ...\n",
            "8    {'MWE_tokens': ['T', 'h', 'i', 's', ' ', 'i', ...\n",
            "9    {'MWE_tokens': ['I', ' ', 'l', 'o', 'v', 'e', ...\n",
            "Name: reviewText_mweTokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHp3Fr9TEuHs",
        "colab_type": "code",
        "outputId": "6a9cbbc6-3456-45f0-856b-d210e598278f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def nltk_postag(sentence):\n",
        "  pos_t=dict()\n",
        "  pos_t[\"Position_Tags\"]=nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
        "  return pos_t\n",
        "\n",
        "df['reviewText_postntag']= df['reviewText'].apply(nltk_postag)\n",
        "print(df[\"reviewText_postntag\"])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Position_Tags': [('I', 'PRP'), ('bought', 'V...\n",
            "1    {'Position_Tags': [('WHY', 'WRB'), ('THIS', 'N...\n",
            "2    {'Position_Tags': [('I', 'PRP'), ('have', 'VBP...\n",
            "3    {'Position_Tags': [('I', 'PRP'), (''ve', 'VBP'...\n",
            "4    {'Position_Tags': [('For', 'IN'), ('simple', '...\n",
            "5    {'Position_Tags': [('While', 'IN'), ('I', 'PRP...\n",
            "6    {'Position_Tags': [('I', 'PRP'), (''ve', 'VBP'...\n",
            "7    {'Position_Tags': [('Bought', 'NNP'), ('this',...\n",
            "8    {'Position_Tags': [('This', 'DT'), ('is', 'VBZ...\n",
            "9    {'Position_Tags': [('I', 'PRP'), ('love', 'VBP...\n",
            "Name: reviewText_postntag, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lecA0FZGd9N",
        "colab_type": "code",
        "outputId": "b7c5267f-c22e-4fa8-b441-003e14e94ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "!pip install pywsd\n",
        "from pywsd.utils import lemmatize_sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pywsd in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pywsd) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.17.4)\n",
            "Requirement already satisfied: wn in /usr/local/lib/python3.6/dist-packages (from pywsd) (0.0.22)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bweFloCUHBDt",
        "colab_type": "code",
        "outputId": "f9ba8def-07cd-484b-c456-1c58e5bab859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def nltk_lemma(sentence):\n",
        "  lemma=dict()\n",
        "  lemma[\"Lemma\"]=lemmatize_sentence(sentence)\n",
        "  return lemma\n",
        "\n",
        "df['reviewText_lemma']= df['reviewText'].apply(nltk_lemma)\n",
        "print(df[\"reviewText_lemma\"])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Lemma': ['i', 'buy', 'my', 'first', 'hp12c',...\n",
            "1    {'Lemma': ['why', 'this', 'belated', 'review',...\n",
            "2    {'Lemma': ['i', 'have', 'an', 'hp', '48gx', 't...\n",
            "3    {'Lemma': ['i', ''ve', 'start', 'do', 'more', ...\n",
            "4    {'Lemma': ['for', 'simple', 'calculation', 'an...\n",
            "5    {'Lemma': ['while', 'i', 'do', 'n't', 'have', ...\n",
            "6    {'Lemma': ['i', ''ve', 'have', 'an', 'hp', '12...\n",
            "7    {'Lemma': ['bought', 'this', 'for', 'my', 'bos...\n",
            "8    {'Lemma': ['this', 'be', 'a', 'well-designed',...\n",
            "9    {'Lemma': ['i', 'love', 'this', 'calculator', ...\n",
            "Name: reviewText_lemma, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWo_AQCXKE4x",
        "colab_type": "code",
        "outputId": "d9362791-1656-4910-eb48-7e631a268738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "def nltk_adjectives(sentence):\n",
        "  adjectives=dict()\n",
        "  adjectives[\"adjectives\"] = [token for token, pos in nltk.pos_tag(word_tokenize(sentence)) if pos.startswith('J')]\n",
        "  return adjectives\n",
        "\n",
        "df['reviewText_adjectives']= df['reviewText'].apply(nltk_adjectives)\n",
        "print(df[\"reviewText_adjectives\"])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'adjectives': ['first', 'difficult', 'many', ...\n",
            "1    {'adjectives': ['old', 'satisfied', 'ower', 'f...\n",
            "2    {'adjectives': ['more', 'more', 'old', 'flawle...\n",
            "3    {'adjectives': ['more', 'good', 'available', '...\n",
            "4    {'adjectives': ['simple', 'best', 'financial',...\n",
            "5    {'adjectives': ['hard', 'undergraduate', 'quic...\n",
            "6    {'adjectives': ['available', 'original', 'esse...\n",
            "7                  {'adjectives': ['great', 'little']}\n",
            "8    {'adjectives': ['well-designed', 'simple', 'ty...\n",
            "9    {'adjectives': ['big', 'calculate', 'easy', 'e...\n",
            "Name: reviewText_adjectives, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}