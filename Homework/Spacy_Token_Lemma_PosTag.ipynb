{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_Token_Lemma_PosTag.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitaliKambli/J025_NLP/blob/master/Homework/Spacy_Token_Lemma_PosTag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qExdQyzTC0_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5d93d028-32f0-4f3f-8d76-8b195269e176"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import urllib, json\n",
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)\n",
        "df=df.head(10)\n",
        "print(df)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
            "0  A32T2H8150OJLU  B00000JBLH  ...     1094169600   09 3, 2004\n",
            "1  A3MAFS04ZABRGO  B00000JBLH  ...     1197676800  12 15, 2007\n",
            "2  A1F1A0QQP2XVH5  B00000JBLH  ...     1293840000   01 1, 2011\n",
            "3   A49R5DBXXQDE5  B00000JBLH  ...     1145404800  04 19, 2006\n",
            "4  A2XRMQA6PJ5ZJ8  B00000JBLH  ...     1375574400   08 4, 2013\n",
            "5  A2JFOHC9W629IE  B00000JBLH  ...     1011744000  01 23, 2002\n",
            "6  A38NELQT98S4H8  B00000JBLH  ...     1168992000  01 17, 2007\n",
            "7   AA8M6331NI1EN  B00000JBLH  ...     1384387200  11 14, 2013\n",
            "8  A25C2M3QF9G7OQ  B00000JBLU  ...     1291680000   12 7, 2010\n",
            "9  A1RTVWTWZSIC94  B00000JBLU  ...     1385942400   12 2, 2013\n",
            "\n",
            "[10 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3R_QdW_C2pd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "47dbde17-c056-4a45-a24c-44dfe7b613cd"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en')\n",
        "def sp_token(sentence):\n",
        "  tokens=dict()\n",
        "  tokens[\"Tokens\"] = sp.tokenizer(sentence)\n",
        "  return tokens\n",
        "\n",
        "df['reviewText_tokens']= df['reviewText'].apply(sp_token)\n",
        "print(df[\"reviewText_tokens\"])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Tokens': (I, bought, my, first, HP12C, in, a...\n",
            "1    {'Tokens': (WHY, THIS, BELATED, REVIEW, ?, I, ...\n",
            "2    {'Tokens': (I, have, an, HP, 48GX, that, has, ...\n",
            "3    {'Tokens': (I, 've, started, doing, more, fina...\n",
            "4    {'Tokens': (For, simple, calculations, and, di...\n",
            "5    {'Tokens': (While, I, do, n't, have, an, MBA, ...\n",
            "6    {'Tokens': (I, 've, had, an, HP, 12C, ever, si...\n",
            "7    {'Tokens': (Bought, this, for, my, boss, becau...\n",
            "8    {'Tokens': (This, is, a, well, -, designed, ,,...\n",
            "9    {'Tokens': (I, love, this, calculator, ,, big,...\n",
            "Name: reviewText_tokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAWRC4fjC-zV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "30ff9a2b-c64d-4301-8b10-681089fce918"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en')\n",
        "\n",
        "def sp_ptag(sentence):\n",
        "  pos_t=[]\n",
        "  pt=dict()\n",
        "  sentence=sp(sentence)\n",
        "  for word in sentence:\n",
        "    pos_t.append(word.pos_)\n",
        "  pt[\"Pos_t\"]=pos_t\n",
        "  return pt\n",
        "\n",
        "df['reviewText_ptag']= df['reviewText'].apply(sp_ptag)\n",
        "print(df[\"reviewText_ptag\"])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Pos_t': ['PRON', 'VERB', 'DET', 'ADJ', 'NOUN...\n",
            "1    {'Pos_t': ['ADV', 'DET', 'ADJ', 'NOUN', 'PUNCT...\n",
            "2    {'Pos_t': ['PRON', 'VERB', 'DET', 'NOUN', 'NUM...\n",
            "3    {'Pos_t': ['PRON', 'VERB', 'VERB', 'VERB', 'AD...\n",
            "4    {'Pos_t': ['ADP', 'ADJ', 'NOUN', 'CCONJ', 'VER...\n",
            "5    {'Pos_t': ['ADP', 'PRON', 'VERB', 'ADV', 'VERB...\n",
            "6    {'Pos_t': ['PRON', 'VERB', 'VERB', 'DET', 'PRO...\n",
            "7    {'Pos_t': ['VERB', 'DET', 'ADP', 'DET', 'NOUN'...\n",
            "8    {'Pos_t': ['DET', 'VERB', 'DET', 'ADV', 'PUNCT...\n",
            "9    {'Pos_t': ['PRON', 'VERB', 'DET', 'NOUN', 'PUN...\n",
            "Name: reviewText_ptag, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0UC19b7DCj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "f1e47f7b-97a2-4267-ceae-07fe50160bee"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en')\n",
        "\n",
        "def sp_lemma(sentence):\n",
        "  lemm=[]\n",
        "  l=dict()\n",
        "  sentence=sp(sentence)\n",
        "  for word in sentence:\n",
        "    lemm.append(word.lemma_)\n",
        "  l[\"Lemma\"]=lemm\n",
        "  return l\n",
        "\n",
        "df['reviewText_lemma']= df['reviewText'].apply(sp_lemma)\n",
        "print(df[\"reviewText_lemma\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Lemma': ['-PRON-', 'buy', '-PRON-', 'first',...\n",
            "1    {'Lemma': ['why', 'this', 'belated', 'review',...\n",
            "2    {'Lemma': ['-PRON-', 'have', 'an', 'hp', '48gx...\n",
            "3    {'Lemma': ['-PRON-', 'have', 'start', 'do', 'm...\n",
            "4    {'Lemma': ['for', 'simple', 'calculation', 'an...\n",
            "5    {'Lemma': ['while', '-PRON-', 'do', 'not', 'ha...\n",
            "6    {'Lemma': ['-PRON-', 'have', 'have', 'an', 'HP...\n",
            "7    {'Lemma': ['buy', 'this', 'for', '-PRON-', 'bo...\n",
            "8    {'Lemma': ['this', 'be', 'a', 'well', '-', 'de...\n",
            "9    {'Lemma': ['-PRON-', 'love', 'this', 'calculat...\n",
            "Name: reviewText_lemma, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wdOfckZDFZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "8e6bc27b-3826-400d-98ec-b9747ab45ff2"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en')\n",
        "\n",
        "def sp_ptag(sentence):\n",
        "  adj=[]\n",
        "  a=dict()\n",
        "  sentence=sp(sentence)\n",
        "  for word in sentence:\n",
        "    if word.tag_.startswith('N'):\n",
        "      adj.append(word)\n",
        "  a[\"adjectives\"]=adj\n",
        "  return a\n",
        "\n",
        "df['reviewText_adj']= df['reviewText'].apply(sp_ptag)\n",
        "print(df[\"reviewText_adj\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'adjectives': [HP12C, one, area, HP, mistake,...\n",
            "1    {'adjectives': [REVIEW, views, workhorse, HP12...\n",
            "2    {'adjectives': [HP, years, HP, years, months, ...\n",
            "3    {'adjectives': [finance, stuff, time, value, m...\n",
            "4    {'adjectives': [calculations, cash, flows, one...\n",
            "5    {'adjectives': [MBA, calculator, business, cou...\n",
            "6    {'adjectives': [HP, years, process, one, one, ...\n",
            "7    {'adjectives': [boss, calculator, day, day, wo...\n",
            "8    {'adjectives': [calculator, function, math, di...\n",
            "9    {'adjectives': [calculator, numbers, calculate...\n",
            "Name: reviewText_adj, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIHMpSbBDKaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "640868d1-af6c-4790-fac5-78918afb9b75"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en')\n",
        "\n",
        "def sp_dparser(sentence):\n",
        "  dep=[]\n",
        "  d=dict()\n",
        "  sentence=sp(sentence)\n",
        "  for word in sentence:\n",
        "    dep.append(word.dep_)\n",
        "  d[\"DepParser\"]=dep\n",
        "  return d\n",
        "\n",
        "df['reviewText_DepParser']= df['reviewText'].apply(sp_dparser)\n",
        "print(df[\"reviewText_DepParser\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'DepParser': ['nsubj', 'ROOT', 'poss', 'amod'...\n",
            "1    {'DepParser': ['advmod', 'nsubj', 'ROOT', 'dob...\n",
            "2    {'DepParser': ['nsubj', 'ROOT', 'det', 'dobj',...\n",
            "3    {'DepParser': ['nsubj', 'aux', 'ROOT', 'xcomp'...\n",
            "4    {'DepParser': ['prep', 'amod', 'pobj', 'cc', '...\n",
            "5    {'DepParser': ['mark', 'nsubj', 'aux', 'neg', ...\n",
            "6    {'DepParser': ['nsubj', 'aux', 'ROOT', 'det', ...\n",
            "7    {'DepParser': ['ROOT', 'dobj', 'prep', 'poss',...\n",
            "8    {'DepParser': ['nsubj', 'ROOT', 'det', 'advmod...\n",
            "9    {'DepParser': ['nsubj', 'ROOT', 'det', 'dobj',...\n",
            "Name: reviewText_DepParser, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}